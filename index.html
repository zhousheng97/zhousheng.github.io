

<!DOCTYPE HTML>

<style>
  #full {
    display: none;
  }
  </style>

<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Haoji Zhang</title>
  
  <meta name="author" content="Sheng Zhou">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/zhousheng.jpg">
</head>


<body>
  <table style="width:100%;max-width:750px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:60%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sheng Zhou (周晟)</name>
              </p>
              <p> 
                I am a Ph.D. student in Computer Science at
                <a href="https://ci.hfut.edu.cn/">Hefei University of Technology</a>. 
                I am fortunate to be supervised by Prof. <a href="https://faculty.hfut.edu.cn/gd/zh_CN/index.htm">Dan Guo</a> and Prof. <a href="https://faculty.hfut.edu.cn/wm12/zh_CN/index.htm">Meng Wang</a>.
              </p> 
              <p>
                My research focuses on vision and language understanding and reasoning. 
                I specialize in fine-grained image and video understanding, with an emphasis on scene text-based QA. 
                Currently, my research focuses on scene-text VideoQA and multimodal large language models.
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=7r9ejvcAAAAJ&hl=zh-CN"> Google Scholar </a> &nbsp/&nbsp
                <a href="hzgn97@gmail.com"> Email </a> &nbsp/&nbsp
                <a href="https://github.com/zhousheng97"> Github </a> &nbsp/&nbsp
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <img style="width:70%;max-width:70%" alt="profile photo" src="images/zhousheng.jpg">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
            <p>
  
              <li style="margin: 5px;" >
                2025.02: <a href="https://github.com/zhousheng97/EgoTextVQA">EgoTextVQA</a> is accepted by <strong style="color: red;">CVPR</strong>. 
              </li>
              <li style="margin: 5px;" >
                2025.02: I honor <a href="https://ci.hfut.edu.cn/info/1063/15439.htm/"> Tat-Seng Chua Scholarship</a>.
              </li>
              <li style="margin: 5px;" >
                2024.09: I will be a visiting student at NUS for one year, collaborating with Postdoc <a href="https://doc-doc.github.io/cv/">Junbin Xiao</a>.
              </li>
              <li style="margin: 5px;" >
                2024.01: <a href="https://github.com/zhousheng97/GPIN">GPIN</a> is accepted by <strong style="color: red;">IEEE TIP</strong>. 
              </li>
              <li style="margin: 5px;" >
                2023.07: Start a study at USTC and supervised by Prof. Xun Yang. 
              </li>
              <li style="margin: 5px;" >
                2023.09: <a href="https://github.com/zhousheng97/SSGN">SSGN</a> is accepted by <strong style="color: red;">IEEE TIP</strong>. 
              </li>
              
            </p>
          </td>
        </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p><heading>Publications and Preprints</heading></p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/adafocus.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>EgoTextVQA: Towards Egocentric Scene-Text Aware Video Question Answering</papertitle>
              <br>
              <strong>Sheng Zhou<strong>, 
                Junbin Xiao, 
                Qingyun Li, 
                Yicong Li, 
                Xun Yang, 
                Dan Guo, 
                Meng Wang, 
                Tat-Seng Chua, 
                Angela Yao;
              <br>
              <em><strong style="color: red;">CVPR</strong></em>
              <br>
              <a href="https://arxiv.org/abs/2502.07411">[arXiv]</a>
              <a href="https://zhousheng97.github.io/EgoTextVQA_page/">[Project Page]</a>
              <a href="https://github.com/zhousheng97/EgoTextVQA">[Code]</a>
              <br>
            </td>
          </tr>
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/ponder.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Scene-Text Grounding for Text-Based Video Question Answering</papertitle>
              <br>
              <strong>Sheng Zhou<strong>, 
                Junbin Xiao, 
                Xun Yang, 
                Peipei Song, 
                Dan Guo, 
                Angela Yao, 
                Meng Wang, 
                Tat-Seng Chua;
              <br>
              <em>Arxiv Preprint, 2024</em>
              <br>
              <a href="https://arxiv.org/abs/2412.01268">[arXiv]</a>
              <a href="https://github.com/zhousheng97/ViTXT-GQA">[Code]</a>
              <br>
            </td>
          </tr>
          
          
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/scclip.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Graph Pooling Inference Network for Text-based VQA</papertitle>
              <br>
              <strong>Sheng Zhou<strong>, 
                Dan Guo, 
                Xun Yang, 
                Jianfeng Dong, 
                Meng Wang;
              <br>
              <em>ACM TOMM, 2024</em>
              <br>
              <a href="https://dl.acm.org/doi/10.1145/3634918">[Paper]</a>
              <a href="https://github.com/zhousheng97/GPIN">[Code]</a>
              <br>
            </td>
          </tr>

                
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src="images/flash_vstream.png" alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Exploring Sparse Spatial Relation in Graph Inference for Text-Based VQA</papertitle>
              <br>
              <strong>Sheng Zhou<strong>, Dan Guo, Jia Li, Xun Yang, Meng Wang;
              <br>
              <em>IEEE TIP, 2023</em>
              <br>
              <a href="https://ieeexplore.ieee.org/document/10241306">[Paper]</a>
              <a href="https://github.com/zhousheng97/SSGN">[Code]</a>
              <br>
            </td>
          </tr>
              

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Honors and Awards</heading>
              <p>
                
                <li style="margin: 5px;"> 
                  Tat-Seng Chua Scholarship, 2025.
                </li>
                <li style="margin: 5px;"> 
                  First Class Academic Scholarship, 2022 - 2025. 
                </li>
                <li style="margin: 5px;"> 
                  Second Class Academic Scholarship, 2020 - 2022. 
                </li>
                <li style="margin: 5px;"> 
                  Outstanding Graduate of Innovation and Entrepreneurship in Hunan Province, 2020. 
                </li>
                <li style="margin: 5px;"> 
                  National Encouragement Scholarship, 2016 - 2019.
                </li>                
              </p>
            </td>
          </tr>
        </tbody></table>

       
  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:5px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">Website Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>

        <p><center>
          <a href="https://clustrmaps.com/site/1c4rm" title="ClustrMaps">
          <img src="//www.clustrmaps.com/map_v2.png?d=Icn5np1Ziy1nrdxuhNF243TFUnolCVjDuXNjTMrnhOg&cl=ffffff" />
          </a>

        </center></p>
      </td>
    </tr>
  </table>
 
</body>

</html>
